{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJeiYrZawUS9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydot as pydot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import plotly.express as px\n",
    "plt.style.use(\"ggplot\")\n",
    "rcParams['figure.figsize'] = (12,6)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn import over_sampling\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XQpnmQ5gmjK"
   },
   "outputs": [],
   "source": [
    "def idx_cm(y_pred, y_test, pos, neg):\n",
    "    fp_rows = []\n",
    "    fn_rows = []\n",
    "    tp_rows = []\n",
    "    tn_rows = []\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == pos and y_test[i] == neg:\n",
    "            fp_rows.append(i)\n",
    "        elif y_pred[i] == pos and y_test[i] == pos:\n",
    "            tp_rows.append(i)\n",
    "        elif y_pred[i] == neg and y_test[i] == pos:\n",
    "            fn_rows.append(i)\n",
    "        elif y_pred[i] == neg and y_test[i] == neg:\n",
    "            tn_rows.append(i)\n",
    "    fp_rows = pd.DataFrame(fp_rows)\n",
    "    tp_rows = pd.DataFrame(tp_rows)\n",
    "    fn_rows = pd.DataFrame(fn_rows)\n",
    "    tn_rows = pd.DataFrame(tn_rows)\n",
    "    cm = [fp_rows, tp_rows, fn_rows, tn_rows]\n",
    "\n",
    "def hypertune_threshold(model, start, stop, X_test, y_test, pos, neg):\n",
    "    threshold = np.linspace(start = start, stop = stop, num = 100)\n",
    "    f1 = np.zeros(threshold.size)\n",
    "    predictions = model.predict_proba(X_test)\n",
    "    for i in np.arange(threshold.size):\n",
    "        probs = np.where(predictions[:,pos]>=threshold[i], pos, neg)\n",
    "        f1[i] = f1_score(np.ravel(y_test), probs, pos_label=pos)\n",
    "    final_probs = np.where(predictions[:,pos]>=threshold[np.argmax(f1)], pos, neg)\n",
    "    return print(threshold[np.argmax(f1)], f1_score(np.ravel(y_test), final_probs, pos_label=pos)), final_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21058,
     "status": "ok",
     "timestamp": 1687416648583,
     "user": {
      "displayName": "Imacakeoholic",
      "userId": "17290791200507014252"
     },
     "user_tz": -120
    },
    "id": "lrKIW5q_znnL",
    "outputId": "559eb670-c06e-45a1-da8c-51ff71460d12"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "root_path = '/content/drive/My Drive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2931,
     "status": "ok",
     "timestamp": 1687416652950,
     "user": {
      "displayName": "Imacakeoholic",
      "userId": "17290791200507014252"
     },
     "user_tz": -120
    },
    "id": "kUx0JPQu0pjZ",
    "outputId": "ab873cdd-ede7-4eda-b349-2a55d32767bd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(122067, 66) (122067, 1) (40690, 66) (40690, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(root_path+'X_train_lvl1.csv')\n",
    "y_train = pd.read_csv(root_path+'y_train_lvl1.csv')\n",
    "X_test = pd.read_csv(root_path+'X_test_lvl1.csv')\n",
    "y_test = pd.read_csv(root_path+'y_test_lvl1.csv')\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train.info()"
   ],
   "metadata": {
    "id": "BZEJXJVi5K_M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBDn4UkLavjr"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_train = ~y_train+2\n",
    "y_test = ~y_test+2\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Training labels shape:', y_resampled.shape)\n",
    "\n",
    "print('Training features shape:', X_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ts549nL7Jrk"
   },
   "source": [
    "# Sklearn XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoqToBD77Nbc"
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=30000, objective = 'binary:logistic',\n",
    "                                   learning_rate = 0.0001,\n",
    "                                   gamma = 0.5, reg_lambda = 0.5,\n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 50, max_leaves=10, early_stopping_rounds = 1000, tree_method = \"gpu_hist\")\n",
    "evalset = [(X_resampled, y_resampled), (X_test,y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "W4_Ag4CsUexF"
   },
   "outputs": [],
   "source": [
    "max_train_size = len(X_train)\n",
    "\n",
    "train_sizes = []\n",
    "auc_roc_scores_test = []\n",
    "f1_scores_test = []\n",
    "brier_scores_test = []\n",
    "loss_scores_test = []\n",
    "auc_roc_scores_train = []\n",
    "f1_scores_train = []\n",
    "brier_scores_train = []\n",
    "loss_scores_train = []\n",
    "\n",
    "for train_size in range(500, max_train_size + 1, 1000):\n",
    "    # Initialize the cross-validation object\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    fold_auc_roc_scores_test = []\n",
    "    fold_f1_scores_test = []\n",
    "    fold_brier_scores_test = []\n",
    "    fold_loss_scores_test = []\n",
    "    fold_auc_roc_scores_train = []\n",
    "    fold_f1_scores_train = []\n",
    "    fold_brier_scores_train = []\n",
    "    fold_loss_scores_train = []\n",
    "\n",
    "    # Split the data into train and test sets using cross-validation\n",
    "    for train_index, test_index in kfold.split(X_train[:train_size], y_train[:train_size]):\n",
    "        X_train_fold, X_test_fold = X_train[:train_size][train_index], X_train[:train_size][test_index]\n",
    "        y_train_fold, y_test_fold = y_train[:train_size][train_index], y_train[:train_size][test_index]\n",
    "\n",
    "    # Normalize data\n",
    "        scaler = preprocessing.MinMaxScaler((0,1))\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        X_test_fold = scaler.transform(X_test_fold)\n",
    "    # Resample train set\n",
    "        ros = RandomUnderSampler(random_state=42)\n",
    "        train_resampled, y_resampled = ros.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Fit the model\n",
    "        model.fit(train_resampled, y_resampled, eval_metric='auc', eval_set=[(train_resampled, y_resampled), (X_test_fold,y_test_fold)], verbose=200)\n",
    "\n",
    "   # Make predictions\n",
    "        y_pred_test = model.predict_proba(X_test_fold)[:,1]\n",
    "        y_pred_train = model.predict_proba(X_train_fold)[:,1]\n",
    "\n",
    "        # Calculate and store the AUC-ROC score\n",
    "        auc_roc_test = roc_auc_score(y_test_fold, y_pred_test)\n",
    "        auc_roc_train = roc_auc_score(y_train_fold, y_pred_train)\n",
    "        fold_auc_roc_scores_test.append(auc_roc_test)\n",
    "        fold_auc_roc_scores_train.append(auc_roc_train)\n",
    "\n",
    "        # Calculate and store the F1 score\n",
    "        y_pred_binary_test = np.round(y_pred_test)\n",
    "        y_pred_binary_train = np.round(y_pred_train)\n",
    "        f1_test = f1_score(y_test_fold, y_pred_binary_test)\n",
    "        f1_train = f1_score(y_train_fold, y_pred_binary_train)\n",
    "        fold_f1_scores_test.append(f1_test)\n",
    "        fold_f1_scores_train.append(f1_train)\n",
    "\n",
    "        # Calculate and store the Brier loss\n",
    "        brier_loss_test = brier_score_loss(y_test_fold, y_pred_test)\n",
    "        fold_brier_scores_test.append(brier_loss_test)\n",
    "        brier_loss_train = brier_score_loss(y_train_fold, y_pred_train)\n",
    "        fold_brier_scores_train.append(brier_loss_train)\n",
    "\n",
    "        # Calculate and store the loss\n",
    "        loss_test = log_loss(y_test_fold, y_pred_test)\n",
    "        fold_loss_scores_test.append(loss_test)\n",
    "        loss_train = log_loss(y_train_fold, y_pred_train)\n",
    "        fold_loss_scores_train.append(loss_train)\n",
    "\n",
    "    # Calculate the average scores across all folds for the current train set size\n",
    "    average_auc_roc_test = np.mean(fold_auc_roc_scores_test)\n",
    "    average_f1_test = np.mean(fold_f1_scores_test)\n",
    "    average_brier_test = np.mean(fold_brier_scores_test)\n",
    "    average_loss_test = np.mean(fold_loss_scores_test)\n",
    "    average_auc_roc_train = np.mean(fold_auc_roc_scores_train)\n",
    "    average_f1_train = np.mean(fold_f1_scores_train)\n",
    "    average_brier_train = np.mean(fold_brier_scores_train)\n",
    "    average_loss_train = np.mean(fold_loss_scores_train)\n",
    "\n",
    "# Append the train set size and average scores to the respective lists\n",
    "    train_sizes.append(train_size)\n",
    "    auc_roc_scores_test.append(average_auc_roc_test)\n",
    "    f1_scores_test.append(average_f1_test)\n",
    "    brier_scores_test.append(average_brier_test)\n",
    "    loss_scores_test.append(average_loss_test)\n",
    "    auc_roc_scores_train.append(average_auc_roc_train)\n",
    "    f1_scores_train.append(average_f1_train)\n",
    "    brier_scores_train.append(average_brier_train)\n",
    "    loss_scores_train.append(average_loss_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBkzE4Oi7xV0"
   },
   "outputs": [],
   "source": [
    "model.fit(X_resampled, y_resampled, eval_metric='logloss', eval_set=evalset, verbose=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQiwCSWQEOC0"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cm = idx_cm(y_pred, y_test, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMAas8TVjG-E"
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Rz8LyN_iyUT"
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(y_prob[tn_rows])\n",
    "plt.xlabel(\"Probability of being 1\")\n",
    "plt.legend('',frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_test[[\"OWNSHIP\", \"AREA\", \"CAR_AVG\", \"SOCGRP_AVG\", \"MARI_STATUS\", \"WEALTH_AVG\", \"HOU_INCO_AVG\", \"USAGE_Apartment\", \"EDU_AVG\"]].iloc[fp_rows[0]].describe()"
   ],
   "metadata": {
    "id": "P9fnBlfy06_b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kcq-ccIcRj8P"
   },
   "outputs": [],
   "source": [
    "print(model.feature_importances_)\n",
    "# plot\n",
    "plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJtOjfRj7mWD"
   },
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "plt.plot(results['validation_0']['logloss'], label='train')\n",
    "plt.plot(results['validation_1']['logloss'], label='test')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.title(\"XGBoost\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5pd6VpiyR0p"
   },
   "outputs": [],
   "source": [
    "f1, final_probs = hypertune_threshold(model, 0.1, 0.6, test, y_test, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMPUiP_wCJ_o"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax= sns.lineplot(x=train_sizes, y=auc_roc_scores_test, label = \"test\")\n",
    "ax1 = sns.lineplot(x=train_sizes, y=auc_roc_scores_train, label = \"train\")\n",
    "ax.set(xlabel='Number of observations', ylabel='ROC_AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pC-J-EaxCTrE"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax= sns.lineplot(x=train_sizes, y=f1_scores_test, label = \"test\")\n",
    "ax1 = sns.lineplot(x=train_sizes, y=f1_scores_train, label = \"train\")\n",
    "ax.set(xlabel='Number of observations', ylabel='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1qAgUzwCaCK"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax= sns.lineplot(x=train_sizes, y=loss_scores_test, label = \"test\")\n",
    "ax1 = sns.lineplot(x=train_sizes, y=loss_scores_train, label = \"train\")\n",
    "ax.set(xlabel='Number of observations', ylabel='Logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfbkk5M1CheH"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax= sns.lineplot(x=train_sizes, y=brier_scores_test, label = \"test\")\n",
    "ax1 = sns.lineplot(x=train_sizes, y=brier_scores_train, label = \"train\")\n",
    "ax.set(xlabel='Number of observations', ylabel='Brier score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpK07j1Uq-k_"
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test,model.predict(X_test))\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square=True, cmap='Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "plt.title(XGBoost, size=15);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1Wxd4xqkH8EGenjcGQbFB1ghnUEBIppqz",
     "timestamp": 1687417163387
    },
    {
     "file_id": "13CBpl2sOOHRfFt22cWPlmReazC2VoFzD",
     "timestamp": 1683634089216
    }
   ],
   "authorship_tag": "ABX9TyP8oRae7gwARz9zJDtgp26X"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
